{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "XGBoost.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Experiment tracking for XGBoost projects"
   ],
   "metadata": {
    "id": "pUggh0PITXzm"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "pip install -U xgboost"
   ],
   "metadata": {
    "id": "WT4yzj18duIo"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JvcjqQV3lC8P"
   },
   "outputs": [],
   "source": [
    "pip install -U layer"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import layer\n",
    "from layer.decorators import model, dataset, resources,pip_requirements, fabric\n",
    "from layer import Dataset"
   ],
   "metadata": {
    "id": "iUhvTvIIlZKZ"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "layer.login()"
   ],
   "metadata": {
    "id": "uP9AjbEhl239"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "layer.init(\"xgboost\")"
   ],
   "metadata": {
    "id": "vTtoQT9dmKud"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!git clone https://github.com/mwitiderrick/experiment-tracking-for-XGBoost-projects.git\n",
    "!mv /content/experiment-tracking-for-XGBoost-projects/heart.csv heart.csv "
   ],
   "metadata": {
    "id": "tfczyN89qm48"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "data_file = 'heart.csv'\n",
    "@resources(data_file)\n",
    "@dataset(\"heart\")\n",
    "def save_data():\n",
    "  import pandas as pd \n",
    "  df = pd.read_csv(data_file)\n",
    "  return df"
   ],
   "metadata": {
    "id": "jNM05mqzl4l_"
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import xgboost as xgb\n",
    "from typing import cast\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "class XGBoostCallback(xgb.callback.TrainingCallback):\n",
    "    def __init__(self,importance_type: str = \"gain\"):\n",
    "      self.importance_type = importance_type\n",
    "\n",
    "    def before_training(self, model):\n",
    "      return model\n",
    "\n",
    "    def after_training(self, model):\n",
    "      if model.attr(\"best_score\") is not None:\n",
    "            print(\n",
    "                {\n",
    "                    \"best_score\": float(cast(str, model.attr(\"best_score\"))),\n",
    "                    \"best_iteration\": int(cast(str, model.attr(\"best_iteration\"))),\n",
    "                }\n",
    "            )\n",
    "\n",
    "\n",
    "      features = model.get_score(importance_type=self.importance_type)\n",
    "      importance = [[feature, features[feature]] for feature in features]\n",
    "\n",
    "      df = pd.DataFrame(data=importance,columns=[\"feature\", \"importance\"])\n",
    "      df = df.sort_values(by='importance', ascending=False)\n",
    "      layer.log({\"Feature Importance Table\": df}) \n",
    "      plt.figure(figsize=(12,8))\n",
    "      plt.xticks(rotation=60, fontsize = 20)\n",
    "      sns.barplot(y=df['feature'], x=df['importance']) \n",
    "\n",
    "      layer.log({\"Feature Importance\": plt.gcf() })\n",
    "\n",
    "      return model\n",
    "\n"
   ],
   "metadata": {
    "id": "XzTWtqfG_LLc"
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "@fabric(\"f-medium\")\n",
    "@model(\"xgboost\",dependencies=[Dataset('heart')])\n",
    "@pip_requirements(packages=[\"matplotlib\",\"seaborn\"])\n",
    "def train():\n",
    "  import xgboost as xgb\n",
    "  import pandas as pd\n",
    "  from sklearn.model_selection import train_test_split\n",
    "  import matplotlib.pyplot as plt\n",
    "  import seaborn as sns\n",
    "  from sklearn.metrics import accuracy_score\n",
    "  from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "  from sklearn.metrics import average_precision_score, roc_auc_score, roc_curve,precision_recall_curve\n",
    "\n",
    "\n",
    "  df = layer.get_dataset(\"heart\").to_pandas()\n",
    "  X = df.drop(['target'],axis=1)\n",
    "  y = df[\"target\"]\n",
    "  test_size = 0.3\n",
    "  random_state = 13\n",
    "  \n",
    "  layer.log({\"test_size\":test_size,\"random_state\":random_state})\n",
    "  params = {\"objective\":\"binary:logistic\",'colsample_bytree': 0.3,'learning_rate': 0.1,\n",
    "                'max_depth': 5, 'alpha': 10}\n",
    "  layer.log(params)\n",
    "  X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=test_size,random_state=random_state)\n",
    "  xgb_model = xgb.XGBClassifier(**params,callbacks=[XGBoostCallback()])\n",
    "  xgb_model.fit(X_train,y_train) \n",
    "  predictions = xgb_model.predict(X_test)\n",
    "  \n",
    "  layer.log({\"Accuracy\" : accuracy_score(predictions, y_test) })\n",
    "  cm = confusion_matrix(y_test, predictions, labels=xgb_model.classes_)\n",
    "  disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=xgb_model.classes_)\n",
    "  disp.plot()\n",
    "  layer.log({\"Confusion metrics\" : plt.gcf()})\n",
    "\n",
    "\n",
    "  probs = xgb_model.predict(X_test)\n",
    "  # Calculate average precision and area under the receiver operating characteric curve (ROC AUC)\n",
    "  avg_precision = average_precision_score(y_test, probs, pos_label=1)\n",
    "  auc = roc_auc_score(y_test, probs)\n",
    "  layer.log({\"AUC\":f'{auc:.4f}'})\n",
    "  layer.log({\"avg_precision\":f'{avg_precision:.4f}'})\n",
    "\n",
    "  sample_preds = X_test\n",
    "  sample_preds[\"predicted\"] = predictions\n",
    "  layer.log({\"Sample predictions\":sample_preds.head(100)})\n",
    "  \n",
    "  return xgb_model"
   ],
   "metadata": {
    "id": "jiQxbr8xmTY-"
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "layer.run([save_data,train])"
   ],
   "metadata": {
    "id": "2t0kKBy-s6aV"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import layer\n",
    "import numpy as np\n",
    "my_model = layer.get_model(\"layer/xgboost/models/xgboost\").get_train()\n",
    "predictions = my_model.predict(np.array([[68,1,2,180,274,1,0,150,1,1.6,1,0,3]]))\n",
    "predictions"
   ],
   "metadata": {
    "id": "Yn7_LyDYsfeo"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Next steps\n",
    "To learn more about using layer, you can: \n",
    "- Join our [Slack Community ](https://bit.ly/layercommunityslack)\n",
    "- Visit [Layer Examples Repo](https://github.com/layerai/examples) for more examples\n",
    "- Browse [Trending Layer Projects](https://layer.ai) on our mainpage\n",
    "- Check out [Layer Documentation](https://docs.app.layer.ai) to learn more"
   ],
   "metadata": {
    "id": "RO8cFS1FTVQZ"
   }
  }
 ]
}